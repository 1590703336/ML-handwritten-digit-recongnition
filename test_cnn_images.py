#!/usr/bin/env python3
"""
æ‰¹é‡éªŒè¯é«˜ç²¾åº¦ CNN æ‰‹å†™æ•°å­—æ¨¡å‹ï¼ˆMNIST 28Ã—28ï¼‰ã€‚

é»˜è®¤ä¼šåŠ è½½ `models/mnist_cnn_best.h5`ï¼ˆ99.68%å‡†ç¡®ç‡çš„é«˜ç²¾åº¦æ¨¡å‹ï¼‰ï¼Œ
å¹¶è¯»å–æŒ‡å®šç›®å½•ä¸‹çš„å›¾ç‰‡æ–‡ä»¶ï¼Œé€å¼ é€å…¥æ¨¡å‹å¹¶æ‰“å°é¢„æµ‹ç»“æœåŠç½®ä¿¡åº¦ã€‚
å¤„ç†ç™½åº•é»‘å­—å›¾ç‰‡ï¼Œè½¬æ¢ä¸º28Ã—28é»‘åº•ç™½å­—æ ¼å¼ã€‚
"""

from __future__ import annotations

import argparse
import sys
from pathlib import Path
from typing import Iterable, List, Sequence, Tuple

import numpy as np
from PIL import Image, ImageOps
import matplotlib.pyplot as plt

try:
    import tensorflow as tf
except ImportError as exc:  # pragma: no cover - ä¾èµ–ç¼ºå¤±æ—¶ç›´æ¥é€€å‡º
    raise SystemExit("âŒ æœªå®‰è£… TensorFlowï¼Œè¯·å…ˆ `pip install tensorflow` åå†è¿è¡Œæœ¬è„šæœ¬ã€‚") from exc

# é…ç½®matplotlibæ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Microsoft YaHei', 'STHeiti', 'Heiti TC']
plt.rcParams['axes.unicode_minus'] = False

DEFAULT_MODEL_PATH = (
    Path(__file__).resolve().parent
    / "models"
    / "mnist_cnn_best.h5"
)
DEFAULT_IMAGE_EXTS = (".png", ".jpg", ".jpeg", ".bmp")

try:
    RESAMPLE = Image.Resampling.LANCZOS
except AttributeError:  # Pillow<9.1
    RESAMPLE = Image.LANCZOS


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="æ‰¹é‡æµ‹è¯•é«˜ç²¾åº¦CNNæ¨¡å‹ï¼ˆ28Ã—28 MNISTï¼‰å¯¹æœ¬åœ°æ‰‹å†™æ•°å­—å›¾ç‰‡çš„è¯†åˆ«æ•ˆæœ")
    parser.add_argument(
        "--model",
        type=Path,
        default=DEFAULT_MODEL_PATH,
        help="keras æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨ mnist_cnn_best.h5ï¼Œå‡†ç¡®ç‡99.68%%ï¼‰",
    )
    parser.add_argument(
        "--images-dir",
        type=Path,
        default=Path("/Users/huanzhang/code/ML/handwritten-digit-recognition/test_cnn_images"),
        help="å¾…æµ‹è¯•å›¾ç‰‡æ‰€åœ¨ç›®å½•",
    )
    parser.add_argument(
        "--scale-max",
        type=float,
        default=255.0,
        help="åƒç´ å½’ä¸€åŒ–æ—¶ä½¿ç”¨çš„æœ€å¤§å€¼ï¼ˆMNISTæ ‡å‡†ä¸º255.0ï¼‰",
    )
    parser.add_argument(
        "--no-invert",
        action="store_true",
        help="ä¸åè‰²ï¼ˆé»˜è®¤ä¼šåè‰²ï¼Œå› ä¸ºç™½åº•é»‘å­—éœ€è¦è½¬æ¢ä¸ºé»‘åº•ç™½å­—ï¼‰",
    )
    parser.add_argument(
        "--ext",
        nargs="*",
        default=None,
        help="è¦çº³å…¥æµ‹è¯•çš„å›¾ç‰‡æ‰©å±•åï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ï¼Œä¾‹å¦‚: --ext .png .jpg",
    )
    parser.add_argument(
        "--visualize",
        action="store_true",
        help="å¯è§†åŒ–æ˜¾ç¤ºæ‰€æœ‰å›¾ç‰‡å’Œé¢„æµ‹ç»“æœ",
    )
    return parser.parse_args()


def collect_images(directory: Path, extensions: Sequence[str]) -> List[Path]:
    exts = tuple(ext.lower() for ext in extensions)
    files = [
        path
        for path in sorted(directory.iterdir())
        if path.is_file() and path.suffix.lower() in exts
    ]
    return files


def ensure_model(model_path: Path) -> tf.keras.Model:
    if not model_path.exists():
        raise SystemExit(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}")
    print(f"âœ… æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    model = tf.keras.models.load_model(model_path)
    input_shape = model.input_shape
    if len(input_shape) != 4:
        raise SystemExit(f"âš ï¸ æš‚ä¸æ”¯æŒè¾“å…¥å½¢çŠ¶ {input_shape} çš„æ¨¡å‹ï¼ˆæœŸæœ›ä¸º N,H,W,Cï¼‰")
    print(f"   æ¨¡å‹è¾“å…¥å½¢çŠ¶: {input_shape}")
    return model


def preprocess_image(
    image_path: Path,
    target_hw: Tuple[int, int],
    channels: int,
    scale_max: float,
    invert: bool,
) -> Tuple[np.ndarray, np.ndarray]:
    """
    é¢„å¤„ç†å›¾ç‰‡ï¼š
    1. è½¬ä¸ºç°åº¦å›¾
    2. åè‰²ï¼ˆç™½åº•é»‘å­— -> é»‘åº•ç™½å­—ï¼ŒMNISTæ ‡å‡†æ ¼å¼ï¼‰
    3. è°ƒæ•´ä¸º28Ã—28
    4. å½’ä¸€åŒ–åˆ°0-1
    
    è¿”å›: (é¢„å¤„ç†åçš„æ•°ç»„, åŸå§‹å›¾ç‰‡æ•°ç»„ç”¨äºå¯è§†åŒ–)
    """
    with Image.open(image_path) as img:
        # ä¿å­˜åŸå§‹å›¾ç‰‡ç”¨äºå¯è§†åŒ–
        original = img.copy()
        
        if channels == 1:
            img = img.convert("L")
            # ç™½åº•é»‘å­— -> é»‘åº•ç™½å­—ï¼ˆMNISTæ ‡å‡†ï¼‰
            if invert:
                img = ImageOps.invert(img)
        else:
            img = img.convert("RGB")
        
        # è°ƒæ•´å¤§å°ä¸º28Ã—28ï¼ˆMNISTæ ‡å‡†ï¼‰
        img = img.resize(target_hw[::-1], RESAMPLE)  # Pillow ä½¿ç”¨ (W,H)
        arr = np.asarray(img, dtype=np.float32)
    
    if channels == 1:
        arr = arr[..., np.newaxis]
    else:
        arr = arr[..., :channels]
    
    # å½’ä¸€åŒ–åˆ°0-1
    max_value = scale_max if scale_max else float(arr.max() or 1.0)
    arr /= max_value
    
    # è½¬æ¢åŸå§‹å›¾ç‰‡ä¸ºæ•°ç»„
    original_arr = np.asarray(original.convert("L"), dtype=np.uint8)
    
    return arr, original_arr


def batch_predict(
    model: tf.keras.Model, tensors: Iterable[np.ndarray]
) -> Tuple[np.ndarray, np.ndarray]:
    batch = np.stack(list(tensors), axis=0)
    predictions = model.predict(batch, verbose=0)
    labels = np.argmax(predictions, axis=1)
    confidences = predictions[np.arange(len(predictions)), labels]
    return labels, confidences


def format_row(values: Sequence[str], widths: Sequence[int]) -> str:
    return " | ".join(text.ljust(width) for text, width in zip(values, widths))


def main() -> None:
    args = parse_args()
    image_exts = args.ext if args.ext else DEFAULT_IMAGE_EXTS
    images = collect_images(args.images_dir, image_exts)
    if not images:
        raise SystemExit(
            f"âš ï¸ ç›®å½• {args.images_dir} å†…æœªæ‰¾åˆ°å›¾ç‰‡ï¼ˆæ”¯æŒæ‰©å±•å: {', '.join(image_exts)}ï¼‰"
        )

    print("="*80)
    print("ğŸš€ é«˜ç²¾åº¦æ‰‹å†™æ•°å­—è¯†åˆ«æµ‹è¯•ï¼ˆMNIST 28Ã—28 æ¨¡å‹ï¼‰")
    print("="*80)
    print(f"ğŸ“ æµ‹è¯•å›¾ç‰‡ç›®å½•: {args.images_dir}")
    print(f"ğŸ“Š æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")
    
    model = ensure_model(args.model)
    _, height, width, channels = model.input_shape
    height = int(height or 0)
    width = int(width or 0)
    channels = int(channels or 1)
    
    if not height or not width:
        raise SystemExit(f"âš ï¸ æ— æ³•ä»æ¨¡å‹è¾“å…¥å½¢çŠ¶ {model.input_shape} æ¨æ–­å°ºå¯¸")
    
    print(f"ğŸ”§ å›¾ç‰‡é¢„å¤„ç†è®¾ç½®:")
    print(f"   - ç›®æ ‡å°ºå¯¸: {height}Ã—{width}")
    print(f"   - åè‰²å¤„ç†: {'å¦' if args.no_invert else 'æ˜¯ï¼ˆç™½åº•é»‘å­—â†’é»‘åº•ç™½å­—ï¼‰'}")
    print(f"   - å½’ä¸€åŒ–: 0-{args.scale_max}")
    
    # é¢„å¤„ç†æ‰€æœ‰å›¾ç‰‡
    invert = not args.no_invert  # é»˜è®¤è¿›è¡Œåè‰²
    processed_data = [
        preprocess_image(img_path, (height, width), channels, args.scale_max, invert)
        for img_path in images
    ]
    tensors = [data[0] for data in processed_data]
    originals = [data[1] for data in processed_data]

    # æ‰¹é‡é¢„æµ‹
    print("\nğŸ§  æ­£åœ¨è¿›è¡Œé¢„æµ‹...")
    preds, confidences = batch_predict(model, tensors)
    
    # æ‰“å°ç»“æœè¡¨æ ¼
    print("\n" + "="*80)
    print("ğŸ“Š é¢„æµ‹ç»“æœ")
    print("="*80)
    header = ["æ–‡ä»¶å", "é¢„æµ‹æ•°å­—", "ç½®ä¿¡åº¦"]
    widths = [max(len(header[0]), 40), len(header[1])+2, len(header[2])+2]
    print(format_row(header, widths))
    print("-" * (sum(widths) + 6))

    for img_path, label, score in zip(images, preds, confidences):
        name = img_path.name[: widths[0]]
        row = [
            name,
            str(int(label)),
            f"{score * 100:5.2f}%",
        ]
        print(format_row(row, widths))

    print("\nâœ… æµ‹è¯•å®Œæˆï¼Œå…±å¤„ç† {} å¼ å›¾ç‰‡ã€‚".format(len(images)))
    
    # ç»Ÿè®¡å‡†ç¡®ç‡ï¼ˆå¦‚æœæ–‡ä»¶ååŒ…å«æ•°å­—æ ‡ç­¾ï¼‰
    correct = 0
    labeled = 0
    for img_path, label in zip(images, preds):
        # å°è¯•ä»æ–‡ä»¶åä¸­æå–æ•°å­—
        for char in img_path.stem:
            if char.isdigit():
                true_label = int(char)
                labeled += 1
                if true_label == label:
                    correct += 1
                break
    
    if labeled > 0:
        acc = correct / labeled * 100
        print(f"\nğŸ“ˆ åœ¨ {labeled} å¼ æœ‰æ ‡ç­¾çš„å›¾ç‰‡ä¸­ï¼Œå‡†ç¡®è¯†åˆ« {correct} å¼ ï¼Œå‡†ç¡®ç‡: {acc:.2f}%")
    
    # å¯è§†åŒ–ç»“æœ
    if args.visualize or True:  # æ€»æ˜¯æ˜¾ç¤ºå¯è§†åŒ–
        print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–ç»“æœ...")
        n_images = len(images)
        n_cols = min(5, n_images)
        n_rows = (n_images + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3.5))
        if n_images == 1:
            axes = np.array([axes])
        axes = axes.flatten()
        
        fig.suptitle('æ‰‹å†™æ•°å­—è¯†åˆ«ç»“æœï¼ˆé«˜ç²¾åº¦CNN - 99.68%å‡†ç¡®ç‡ï¼‰', 
                     fontsize=16, fontweight='bold')
        
        for i, (img_path, original, label, score) in enumerate(zip(images, originals, preds, confidences)):
            ax = axes[i]
            ax.imshow(original, cmap='gray')
            
            # æ˜¾ç¤ºæ–‡ä»¶åï¼ˆç¼©çŸ­ï¼‰
            filename = img_path.name
            if len(filename) > 20:
                filename = filename[:17] + "..."
            
            title = f'{filename}\né¢„æµ‹: {label} (ç½®ä¿¡åº¦: {score*100:.1f}%)'
            
            # å¦‚æœç½®ä¿¡åº¦å¾ˆé«˜ï¼Œç”¨ç»¿è‰²ï¼›ä¸­ç­‰ç”¨é»„è‰²ï¼›ä½ç”¨çº¢è‰²
            if score >= 0.95:
                color = 'green'
            elif score >= 0.80:
                color = 'orange'
            else:
                color = 'red'
            
            ax.set_title(title, fontsize=9, color=color, fontweight='bold')
            ax.axis('off')
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(n_images, len(axes)):
            axes[i].axis('off')
        
        plt.tight_layout()
        
        # ä¿å­˜ç»“æœ
        output_path = Path('outputs/visualizations/15_test_results.png')
        output_path.parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜: {output_path}")
        plt.show()
        
    print("\n" + "="*80)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        sys.exit("\nç”¨æˆ·ä¸­æ–­ã€‚")

